{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06920b65",
   "metadata": {},
   "source": [
    "\n",
    "# <span style=\"color:DarkSeaGreen\">JumpStart Lab 2</span>\n",
    "\n",
    "This lab does the following:\n",
    "\n",
    "- Uses the endpoint created in Lab 1\n",
    "- Implements SageMaker application-autoscaling\n",
    "- Tests the functionality \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb29b8",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">Prepare Your Environment</span>\n",
    "### Note if you want a venv, see Lab 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbb8cd5",
   "metadata": {},
   "source": [
    "# Lab 2 Starts Here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd86ebb0",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">Setup</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40fc3db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# region\n",
    "# for the purpose of this lab, us-east-1, us-west-2, eu-west-1 has the broadest coverage of JumpStart models and instance types\n",
    "# if you provision in other regions, you may not have access to all the models or instance types, and may need to request increase of quotas for some instance types\n",
    "myRegion='us-east-1'\n",
    "\n",
    "# parameter store\n",
    "myParameterStoreEndpointName='doit-jumpstart-sagemaker-endpoint-name'\n",
    "myParameterStoreIAMARN='doit-jumpstart-sagemaker-iam-arn'\n",
    "\n",
    "# application auto scaling policy\n",
    "myEndpointScalingPolicyName='doit-jumpstart-sagemaker-endpoint-scaling-policy'\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb4a28a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546709318047\n",
      "arn:aws:iam::546709318047:user/simon-davies-cli\n",
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import boto3\n",
    "from certifi import where\n",
    "\n",
    "botoSession = boto3.Session(region_name=myRegion)\n",
    "\n",
    "# Configure boto3 to use certifi's certificates - helps avoid SSL errors if your systemâ€™s certificate store is out of date or missing root certs\n",
    "sts_client = boto3.client('sts', verify=where())\n",
    "myAccountNumber = sts_client.get_caller_identity()[\"Account\"]\n",
    "print(myAccountNumber)\n",
    "print(sts_client.get_caller_identity()[\"Arn\"])\n",
    "\n",
    "# create clients we can use later\n",
    "# iam\n",
    "iam = boto3.client('iam', region_name=myRegion, verify=where())\n",
    "# ssm\n",
    "ssm = boto3.client('ssm', region_name=myRegion, verify=where())\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01b6da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# define tags added to all services we create\n",
    "myTags = [\n",
    "    {\"Key\": \"env\", \"Value\": \"non_prod\"},\n",
    "    {\"Key\": \"owner\", \"Value\": \"doit-jumpstart\"},\n",
    "    {\"Key\": \"project\", \"Value\": \"lab1\"},\n",
    "    {\"Key\": \"author\", \"Value\": \"simon\"},\n",
    "]\n",
    "myTagsDct = {\n",
    "    \"env\": \"non_prod\",\n",
    "    \"owner\": \"doit-jumpstart\",\n",
    "    \"project\": \"lab1\",\n",
    "    \"author\": \"simon\",\n",
    "}\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076a8523",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">IAM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e457fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSageMakerExecutionRole():\n",
    "    \"\"\"\n",
    "    Gets a role required for SageMaker to run jobs on your behalf\n",
    "    Only needed if this is being run in a local IDE, not needed if in SageMaker Studio or SageMaker Notebook Instance\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        An IAM execution role ARN\n",
    "    \"\"\"\n",
    "\n",
    "    # get the role we created in the previous lab from the parameter store\n",
    "    response = ssm.get_parameter(Name=myParameterStoreIAMARN)\n",
    "    myRoleSageMakerExecutionARN = response['Parameter']['Value']\n",
    "    print(f\"Retrieved role from parameter store: {myRoleSageMakerExecutionARN}\")    \n",
    "\n",
    "    return myRoleSageMakerExecutionARN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708857ff",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">Get Execution Role and Session</span>\n",
    "- SageMaker requires an execution role to assume on your behalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80e08fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name simon-davies-cli to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved role from parameter store: arn:aws:iam::546709318047:role/doit-jumpstart-sagemaker-execution-role\n",
      "arn:aws:iam::546709318047:role/doit-jumpstart-sagemaker-execution-role\n",
      "<sagemaker.session.Session object at 0x10c6783e0>\n",
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.session import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "try:\n",
    "    # if this is being run in a SageMaker AI JupyterLab Notebook\n",
    "    myRoleSageMakerExecutionARN = get_execution_role()\n",
    "except:\n",
    "    # if this is being run in a local IDE - we need to create our own role\n",
    "    myRoleSageMakerExecutionARN = getSageMakerExecutionRole()\n",
    "\n",
    "# make sure we get a session in the correct region (needed as it can use the aws configure region if running this locally\n",
    "sageMakerSession = Session(boto_session=botoSession)\n",
    "\n",
    "print(myRoleSageMakerExecutionARN)\n",
    "print(sageMakerSession)\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553bb10",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">Get the Endpoint from Lab 1</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcada497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint name: meta-textgeneration-llama-2-7b-2025-09-23-07-37-06-134\n",
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# get the endpoint created in lab1\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# get the endpoint name from parameter store\n",
    "response = ssm.get_parameter(\n",
    "    Name=myParameterStoreEndpointName\n",
    ")\n",
    "endpointName = response['Parameter']['Value']\n",
    "print(f\"Using endpoint name: {endpointName}\")  \n",
    "\n",
    "# create a predictor to interact with the endpoint - need to specify the default serializer and deserializer this time\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpointName,\n",
    "    sagemaker_session=sageMakerSession,\n",
    "    serializer=JSONSerializer(),      \n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f31cd654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " {'inputs': 'Write a Python function to check if a number is prime', 'parameters': {'max_new_tokens': 128, 'temperature': 0.2, 'top_p': 0.9}}\n",
      "\n",
      "Output:\n",
      " Write a Python function to check if a number is prime or not.\n",
      "Write a Python function to check if a number is prime or not. The function should take a number as input and return True if the number is prime and False otherwise.\n",
      "Write a Python function to check if a number is prime or not. The function should take a number as input and return True if the number is prime and False otherwise. The function should use the Sieve of Eratosthenes algorithm to check if the number is prime or not.\n",
      "The Sieve of Eratosthenes algorithm is a simple and efficient way to check if a number is prime or not. The algorithm works by\n",
      "\n",
      "\n",
      "Input:\n",
      " {'inputs': 'Describe what a llm model can do for someone who is sceptical about them', 'parameters': {'max_new_tokens': 128, 'temperature': 0.2, 'top_p': 0.9}}\n",
      "\n",
      "Output:\n",
      " Describe what a llm model can do for someone who is sceptical about them.\n",
      "The LLM model is a powerful tool for those who are sceptical about it. It can help you to understand the law and how it applies to your situation. It can also help you to make informed decisions about your legal rights and responsibilities.\n",
      "Explain the benefits of using an llm model.\n",
      "There are many benefits to using an llm model. One of the most important benefits is that it can help you to understand the law and how it applies to your situation. It can also help you to make informed decisions about your legal rights and responsibilities.\n",
      "Describe the different types\n",
      "\n",
      "\n",
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# test the endpoint\n",
    "example_payloads = [\n",
    "    {\n",
    "        \"body\": {\n",
    "            \"inputs\": \"Write a Python function to check if a number is prime\",\n",
    "            \"parameters\": {\"max_new_tokens\": 128, \"temperature\": 0.2, \"top_p\": 0.9},\n",
    "        },\n",
    "        \"content_type\": \"application/json\",\n",
    "        \"accept\": \"application/json\",\n",
    "    },\n",
    "    {\n",
    "        \"body\": {\n",
    "            \"inputs\": \"Describe what a llm model can do for someone who is sceptical about them\",\n",
    "            \"parameters\": {\"max_new_tokens\": 128, \"temperature\": 0.2, \"top_p\": 0.9},\n",
    "        },\n",
    "        \"content_type\": \"application/json\",\n",
    "        \"accept\": \"application/json\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "for payload in example_payloads:\n",
    "    body = payload.body if hasattr(payload, \"body\") else payload[\"body\"]\n",
    "    response = predictor.predict(body)\n",
    "    response = response[0] if isinstance(response, list) else response\n",
    "    print(\"Input:\\n\", body, end=\"\\n\\n\")\n",
    "    print(\"Output:\\n\", response[\"generated_text\"].strip(), end=\"\\n\\n\\n\")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e923450",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">Create Scalability Plan</span>\n",
    "- Uses SageMaker Application Auto Scaling\n",
    "- Works especially well for generative AI models, which are typically concurrency-bound and can take many seconds to complete each inference request\n",
    "- Using the new high-resolution metrics allow you to greatly decrease the time it takes to scale up an endpoint using Application Auto Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef977508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/aws/amazon-sagemaker-examples/blob/main/inference/generativeai/huggingfacetgi/meta-llama/llama3-8b/faster-autoscaling/realtime-endpoints/FasterAutoscaling-SME-Llama3-8B-AppAutoScaling.ipynb\n",
    "# https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-inference-launches-faster-auto-scaling-for-generative-ai-models/\n",
    "# https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html\n",
    "\n",
    "# define a new auto scaling target for Application Auto Scaling\n",
    "# auto scaling\n",
    "autoScaling = boto3.client('application-autoscaling', region_name=myRegion, verify=where())\n",
    "variantName = \"AllTraffic\"\n",
    "ResourceId  = \"endpoint/\" + endpointName + \"/variant/\" + variantName\n",
    "\n",
    "# Register scalable target\n",
    "scalableTarget = autoScaling.register_scalable_target(\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=ResourceId,\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=2,  # Replace with your desired maximum instances\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb06527f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# create target tracking scaling policy\n",
    "# this is a target tracking policy that uses the new high-resolution metrics for SageMaker endpoints\n",
    "# you can also create a step-scaling policy if you prefer\n",
    "# a step-scaling policy is more complex to set up, but gives you more control over how your endpoint scales\n",
    "\n",
    "# create a policy that scales out when the endpoint receives more than n ConcurrentRequestsPerModel\n",
    "# this new metric will be tracked when th predefined metric type used below is SageMakerVariantConcurrentRequestsPerModelHighResolution\n",
    "targetTrackingPolicyResponse = autoScaling.put_scaling_policy(\n",
    "    PolicyName=myEndpointScalingPolicyName,\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=ResourceId,\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    PolicyType=\"TargetTrackingScaling\",\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        \"TargetValue\": 5.0,  # Scaling triggers when endpoint receives 5 ConcurrentRequestsPerModel\n",
    "        \"PredefinedMetricSpecification\": {\n",
    "            \"PredefinedMetricType\": \"SageMakerVariantConcurrentRequestsPerModelHighResolution\"\n",
    "        },\n",
    "        \"ScaleInCooldown\": 180,  # Cooldown period after scale-in activity\n",
    "        \"ScaleOutCooldown\": 180,  # Cooldown period after scale-out activity\n",
    "    },\n",
    ")\n",
    "\n",
    "# print(target_tracking_policy_response)\n",
    "print(f\"[b]Policy ARN:[/b] [i blue]{targetTrackingPolicyResponse['PolicyARN']}\")\n",
    "\n",
    "# print Cloudwatch Alarms\n",
    "alarms = targetTrackingPolicyResponse[\"Alarms\"]\n",
    "\n",
    "for alarm in alarms:\n",
    "    print(f\"[b]Alarm Name:[/b] [b magenta]{alarm['AlarmName']}\")\n",
    "    # print(f\"[b]Alarm ARN:[/b] [i green]{alarm['AlarmARN']}[/i green]\")\n",
    "    print(\"===\" * 15)\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece097a3",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">Test Scalability Plan</span>\n",
    "- Lets just test the endpoint first, make sure its all good\n",
    "- Simulate load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d5392bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " {'inputs': 'Please explain what load testing is and why its important in reference to sagemaker endpoints', 'parameters': {'max_new_tokens': 128, 'temperature': 0.2, 'top_p': 0.9}}\n",
      "\n",
      "Output:\n",
      " Please explain what load testing is and why its important in reference to sagemaker endpoints.\n",
      "Load testing is a type of performance testing that measures the behavior of a system under a specific load. It is important in reference to SageMaker endpoints because it helps to ensure that the system can handle the expected load and provides a baseline for future performance.\n",
      "Load testing helps to identify any potential bottlenecks or issues that may arise when the system is under a heavy load. It also helps to ensure that the system is scalable and can handle an increase in traffic.\n",
      "Load testing is important in reference to SageMaker endpoints because it helps to ensure that the system can handle the expected load\n",
      "\n",
      "\n",
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# lets just test the endpoint again to make sure it still works\n",
    "example_payloads = [\n",
    "    {\n",
    "        \"body\": {\n",
    "            \"inputs\": \"Please explain what load testing is and why its important in reference to sagemaker endpoints\",\n",
    "            \"parameters\": {\"max_new_tokens\": 128, \"temperature\": 0.2, \"top_p\": 0.9},\n",
    "        },\n",
    "        \"content_type\": \"application/json\",\n",
    "        \"accept\": \"application/json\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for payload in example_payloads:\n",
    "    body = payload.body if hasattr(payload, \"body\") else payload[\"body\"]\n",
    "    response = predictor.predict(body)\n",
    "    response = response[0] if isinstance(response, list) else response\n",
    "    print(\"Input:\\n\", body, end=\"\\n\\n\")\n",
    "    print(\"Output:\\n\", response[\"generated_text\"].strip(), end=\"\\n\\n\\n\")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c1f7fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export AWS_REGION=us-east-1\n",
      "export ENDPOINT_NAME=meta-textgeneration-llama-2-7b-2025-09-23-07-37-06-134\n",
      "export CONTENT_TYPE=application/json\n",
      "export PAYLOAD='{\"inputs\": \"I am going to siulate a load test on your endpoint in a few minutes. What do you think of that?\"}'\n",
      "export HOST=http://localhost\n"
     ]
    }
   ],
   "source": [
    "# now we're going to use locust to simulate load on the endpoint\n",
    "# https://docs.locust.io/en/stable/ \n",
    "# https://aws.amazon.com/blogs/machine-learning/best-practices-for-load-testing-amazon-sagemaker-real-time-inference-endpoints/\n",
    "# see the locust_script_lab2.py file for details of the load test\n",
    "# it gathers the endpoint name, etc via os environment vars we export below\n",
    "# run this cell, then paste and run in a terminal window, make sure its run in your virtual environment created in lab 1, or in your own that has boto3 and locust installed\n",
    "\n",
    "print (\"export AWS_REGION={}\".format(myRegion))\n",
    "print (\"export ENDPOINT_NAME={}\".format(endpointName))\n",
    "print (\"export CONTENT_TYPE={}\".format(\"application/json\"))\n",
    "print (\"export PAYLOAD='{}'\".format('{\"inputs\": \"I am going to siulate a load test on your endpoint in a few minutes. What do you think of that?\"}'))\n",
    "print (\"export HOST={}\".format('http://localhost')) # locust needs a host, but we don't use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94932b41",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# these are picked up by the locust file\n",
    "# Paste the following in a terminal window, make sure its run in your virtual environment created in lab 1, or in your own that has boto3 and locust installed\n",
    "# LOCUST_USERS is the number of simulated users\n",
    "# LOCUST_SPAWN_RATE is the rate per second to spawn (add new) users - so 20 users at rate of 2 means add 2 users every second, so take 10 seconds to get to 20 users\n",
    "# LOCUST_RUN_TIME is how long to run the test for\n",
    "export LOCUST_USERS=20\n",
    "export LOCUST_SPAWN_RATE=2\n",
    "export LOCUST_RUN_TIME=10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fa72d8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# now we're going to use locust to simulate load on the endpoint\n",
    "# https://docs.locust.io/en/stable/ \n",
    "# https://aws.amazon.com/blogs/machine-learning/best-practices-for-load-testing-amazon-sagemaker-real-time-inference-endpoints/\n",
    "# see the locust_script_lab2.py file for details of the load test\n",
    "# it gathers the endpoint name, etc from the parameter store where we stored it in lab 1\n",
    "\n",
    "# Paste the following in a terminal window, make sure its run in your virtual environment created in lab 1, or in your own that has boto3 and locust installed\n",
    "locust -f locust_script_lab2.py --headless -u $LOCUST_USERS -r $LOCUST_SPAWN_RATE --run-time $LOCUST_RUN_TIME --host http://localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be23fb",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">White Locust is Running</span>\n",
    "- Go to the CloudWatch console\n",
    "- Monitor the alarm being target tracked for ConcurrentRequestsPerModel, eg \n",
    "  - TargetTracking-endpoint/*endpoint name*-Alarm**High**-*uuid*\n",
    "  - TargetTracking-endpoint/*endpoint name*-Alarm**Low**-*uuid*\n",
    "- Run the cell below to monitor the instance count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b70bcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring endpoint 'meta-textgeneration-llama-2-7b-2025-09-23-07-37-06-134' variants (press Ctrl+C to stop)...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_s/nlp433gs2q54y8h1j_pp0p240000gn/T/ipykernel_64510/2384411520.py:25: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  end_time = datetime.utcnow()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:21:13] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:21:24] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:21:36] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:21:47] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:21:59] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:22:10] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:22:22] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:22:33] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:22:45] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:22:56] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:23:08] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:23:19] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:23:31] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:23:42] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:23:54] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:24:05] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:24:17] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:24:28] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:24:40] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:24:51] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:25:02] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:25:15] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:25:26] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:25:38] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:25:49] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:26:01] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:26:12] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:26:24] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:26:35] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:26:46] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:26:58] Variant: AllTraffic | Current instances: 1 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:27:09] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:27:21] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 20.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:27:32] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 10.5\n",
      "--------------------------------------------------------------------------------\n",
      "[18:27:44] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 10.5\n",
      "--------------------------------------------------------------------------------\n",
      "[18:27:55] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 13.5\n",
      "--------------------------------------------------------------------------------\n",
      "[18:28:07] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 13.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:28:18] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 13.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:28:30] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 13.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:28:41] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 12.5\n",
      "--------------------------------------------------------------------------------\n",
      "[18:28:54] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 12.5\n",
      "--------------------------------------------------------------------------------\n",
      "[18:29:05] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 13.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:29:17] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 13.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:29:29] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 13.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:29:40] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 12.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:29:52] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 14.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:30:03] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 14.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:30:15] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 12.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:30:26] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 14.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:30:37] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 14.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:30:49] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 14.5\n",
      "--------------------------------------------------------------------------------\n",
      "[18:31:00] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 14.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:31:12] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 14.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:31:23] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 13.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:31:35] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 13.5\n",
      "--------------------------------------------------------------------------------\n",
      "[18:31:46] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 13.5\n",
      "--------------------------------------------------------------------------------\n",
      "[18:31:58] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:32:09] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:32:21] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:32:32] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:32:44] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:32:55] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:33:07] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:33:19] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:33:30] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:33:42] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:33:55] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:34:06] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:34:18] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:34:29] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:34:41] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:34:52] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:35:04] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:35:15] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:35:27] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:35:39] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:35:50] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:36:02] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:36:13] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:36:25] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:36:36] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:36:47] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:36:59] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:37:10] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:37:23] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:37:34] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:37:45] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:37:57] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:38:08] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:38:20] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:38:31] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:38:43] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:38:54] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:39:06] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:39:17] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:39:29] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:39:40] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:39:51] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:40:03] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:40:14] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:40:26] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:40:37] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:40:49] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:41:00] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:41:12] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:41:23] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:41:36] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:41:47] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:41:59] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:42:10] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:42:22] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:42:33] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:42:45] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:42:56] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:43:08] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:43:19] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:43:30] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:43:42] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:43:54] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:44:05] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:44:17] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:44:28] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:44:39] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:44:51] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:45:02] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:45:14] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:45:25] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:45:38] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:45:49] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:46:01] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:46:12] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:46:24] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:46:35] Variant: AllTraffic | Current instances: 2 | Desired instances: 2 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:46:47] Variant: AllTraffic | Current instances: 2 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:46:58] Variant: AllTraffic | Current instances: 2 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:47:10] Variant: AllTraffic | Current instances: 2 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:47:21] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:47:33] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:47:44] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:47:56] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:48:07] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:48:19] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:48:30] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:48:42] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:48:53] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:49:05] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:49:16] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:49:28] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:49:40] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:49:51] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:50:03] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:50:14] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:50:26] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:50:37] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:50:49] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:51:00] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:51:12] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:51:23] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:51:35] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:51:46] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:51:58] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:52:09] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:52:21] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:52:32] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:52:44] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:52:55] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:53:07] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:53:18] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:53:30] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:53:42] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "[18:53:54] Variant: AllTraffic | Current instances: 1 | Desired instances: 1 | ConcurrentRequestsPerModel: 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "Monitoring stopped.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- Configuration ---\n",
    "endpoint_name = endpointName\n",
    "region = myRegion\n",
    "poll_interval = 10    # seconds between checks\n",
    "\n",
    "# --- Clients ---\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "cw_client = boto3.client(\"cloudwatch\", region_name=region)\n",
    "\n",
    "print(f\"Monitoring endpoint '{endpoint_name}' variants (press Ctrl+C to stop)...\\n\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # --- Describe endpoint variants ---\n",
    "        response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        for variant in response[\"ProductionVariants\"]:\n",
    "            variant_name = variant[\"VariantName\"]\n",
    "            current_instances = variant[\"CurrentInstanceCount\"]\n",
    "            desired_instances = variant[\"DesiredInstanceCount\"]\n",
    "\n",
    "            # --- Fetch latest ConcurrentRequestsPerModel metric ---\n",
    "            end_time = datetime.utcnow()\n",
    "            start_time = end_time - timedelta(seconds=poll_interval*2)  # small window to get the latest datapoint\n",
    "\n",
    "            metric_resp = cw_client.get_metric_statistics(\n",
    "                Namespace=\"AWS/SageMaker\",\n",
    "                MetricName=\"ConcurrentRequestsPerModel\",\n",
    "                Dimensions=[\n",
    "                    {\"Name\": \"EndpointName\", \"Value\": endpoint_name},\n",
    "                    {\"Name\": \"VariantName\", \"Value\": variant_name},\n",
    "                ],\n",
    "                StartTime=start_time,\n",
    "                EndTime=end_time,\n",
    "                Period=poll_interval,\n",
    "                Statistics=[\"Average\"],\n",
    "            )\n",
    "\n",
    "            datapoints = metric_resp.get(\"Datapoints\", [])\n",
    "            concurrent_requests = round(datapoints[-1][\"Average\"], 2) if datapoints else 0\n",
    "\n",
    "            print(\n",
    "                f\"[{time.strftime('%H:%M:%S')}] Variant: {variant_name} | \"\n",
    "                f\"Current instances: {current_instances} | Desired instances: {desired_instances} | \"\n",
    "                f\"ConcurrentRequestsPerModel: {concurrent_requests}\"\n",
    "            )\n",
    "\n",
    "        print(\"-\" * 80)\n",
    "        time.sleep(poll_interval)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Monitoring stopped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c3d83b",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">SageMaker Inference Recommender</span>\n",
    "- Helps you select the best instance type and configuration for your ML models and workloads\n",
    "- https://docs.aws.amazon.com/sagemaker/latest/dg/inference-recommender.html\n",
    "- NOTE NEEDS TO BE INVESTIGATED TO SEE IF IT WORKS WITH LLM REAL TIME ENDPOINTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddfc496",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">Clean Up Architecture</span>\n",
    "### <span style=\"color:Red\">Only do this if you have finished with this lab and any labs that depend on it!</span>\n",
    "##### It will delete all architecture created, make sure you no longer need any of it!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when finished with the endpoint, delete it\n",
    "# endpoint is deleted in lab 1\n",
    "# remmeber to delete the architecture in lab 1 too"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

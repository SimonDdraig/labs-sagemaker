{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06920b65",
   "metadata": {},
   "source": [
    "\n",
    "# <span style=\"color:DarkSeaGreen\">JumpStart Lab 2</span>\n",
    "\n",
    "This lab does the following:\n",
    "\n",
    "- Uses the endpoint created in Lab 1\n",
    "- Implements SageMaker application-autoscaling\n",
    "- Tests the functionality \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb29b8",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">Prepare Your Environment</span>\n",
    "### Note if you want a venv, see Lab 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbb8cd5",
   "metadata": {},
   "source": [
    "# Lab 2 Starts Here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd86ebb0",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">Setup</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# region\n",
    "# for the purpose of this lab, us-east-1, us-west-2, eu-west-1 has the broadest coverage of JumpStart models and instance types\n",
    "# if you provision in other regions, you may not have access to all the models or instance types, and may need to request increase of quotas for some instance types\n",
    "myRegion='us-east-1'\n",
    "\n",
    "# parameter store\n",
    "myParameterStoreEndpointName='doit-jumpstart-sagemaker-endpoint-name'\n",
    "myParameterStoreIAMARN='doit-jumpstart-sagemaker-iam-arn'\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a28a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import boto3\n",
    "from certifi import where\n",
    "\n",
    "botoSession = boto3.Session(region_name=myRegion)\n",
    "\n",
    "# Configure boto3 to use certifi's certificates - helps avoid SSL errors if your systemâ€™s certificate store is out of date or missing root certs\n",
    "sts_client = boto3.client('sts', verify=where())\n",
    "myAccountNumber = sts_client.get_caller_identity()[\"Account\"]\n",
    "print(myAccountNumber)\n",
    "print(sts_client.get_caller_identity()[\"Arn\"])\n",
    "\n",
    "# create clients we can use later\n",
    "# iam\n",
    "iam = boto3.client('iam', region_name=myRegion, verify=where())\n",
    "# ssm\n",
    "ssm = boto3.client('ssm', region_name=myRegion, verify=where())\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tags added to all services we create\n",
    "myTags = [\n",
    "    {\"Key\": \"env\", \"Value\": \"non_prod\"},\n",
    "    {\"Key\": \"owner\", \"Value\": \"doit-jumpstart\"},\n",
    "    {\"Key\": \"project\", \"Value\": \"lab1\"},\n",
    "    {\"Key\": \"author\", \"Value\": \"simon\"},\n",
    "]\n",
    "myTagsDct = {\n",
    "    \"env\": \"non_prod\",\n",
    "    \"owner\": \"doit-jumpstart\",\n",
    "    \"project\": \"lab1\",\n",
    "    \"author\": \"simon\",\n",
    "}\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076a8523",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">IAM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSageMakerExecutionRole():\n",
    "    \"\"\"\n",
    "    Gets a role required for SageMaker to run jobs on your behalf\n",
    "    Only needed if this is being run in a local IDE, not needed if in SageMaker Studio or SageMaker Notebook Instance\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        An IAM execution role ARN\n",
    "    \"\"\"\n",
    "\n",
    "    # get the role we created in the previous lab from the parameter store\n",
    "    response = ssm.get_parameter(Name=myParameterStoreIAMARN)\n",
    "    myRoleSageMakerExecutionARN = response['Parameter']['Value']\n",
    "    print(f\"Retrieved role from parameter store: {myRoleSageMakerExecutionARN}\")    \n",
    "\n",
    "    return myRoleSageMakerExecutionARN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708857ff",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">Get Execution Role and Session</span>\n",
    "- SageMaker requires an execution role to assume on your behalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e08fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "try:\n",
    "    # if this is being run in a SageMaker AI JupyterLab Notebook\n",
    "    myRoleSageMakerExecutionARN = get_execution_role()\n",
    "except:\n",
    "    # if this is being run in a local IDE - we need to create our own role\n",
    "    myRoleSageMakerExecutionARN = getSageMakerExecutionRole()\n",
    "\n",
    "# make sure we get a session in the correct region (needed as it can use the aws configure region if running this locally\n",
    "sageMakerSession = Session(boto_session=botoSession)\n",
    "\n",
    "print(myRoleSageMakerExecutionARN)\n",
    "print(sageMakerSession)\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553bb10",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">Get the Endpoint from Lab 1</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcada497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the endpoint created in lab1\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# get the endpoint name from parameter store\n",
    "response = ssm.get_parameter(\n",
    "    Name=myParameterStoreEndpointName\n",
    ")\n",
    "endpoint_name = response['Parameter']['Value']\n",
    "print(f\"Using endpoint name: {endpoint_name}\")  \n",
    "\n",
    "# create a predictor to interact with the endpoint - need to specify the default serializer and deserializer this time\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sageMakerSession,\n",
    "    serializer=JSONSerializer(),      \n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cd654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the endpoint\n",
    "example_payloads = [\n",
    "    {\n",
    "        \"body\": {\n",
    "            \"inputs\": \"Write a Python function to check if a number is prime\",\n",
    "            \"parameters\": {\"max_new_tokens\": 128, \"temperature\": 0.2, \"top_p\": 0.9},\n",
    "        },\n",
    "        \"content_type\": \"application/json\",\n",
    "        \"accept\": \"application/json\",\n",
    "    },\n",
    "    {\n",
    "        \"body\": {\n",
    "            \"inputs\": \"Describe what a llm model can do for someone who is sceptical about them\",\n",
    "            \"parameters\": {\"max_new_tokens\": 128, \"temperature\": 0.2, \"top_p\": 0.9},\n",
    "        },\n",
    "        \"content_type\": \"application/json\",\n",
    "        \"accept\": \"application/json\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "for payload in example_payloads:\n",
    "    body = payload.body if hasattr(payload, \"body\") else payload[\"body\"]\n",
    "    response = predictor.predict(body)\n",
    "    response = response[0] if isinstance(response, list) else response\n",
    "    print(\"Input:\\n\", body, end=\"\\n\\n\")\n",
    "    print(\"Output:\\n\", response[\"generated_text\"].strip(), end=\"\\n\\n\\n\")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e923450",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">Create Scalability Plan</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef977508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/aws/amazon-sagemaker-examples/blob/main/inference/generativeai/huggingfacetgi/meta-llama/llama3-8b/faster-autoscaling/realtime-endpoints/FasterAutoscaling-SME-Llama3-8B-AppAutoScaling.ipynb\n",
    "# https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-inference-launches-faster-auto-scaling-for-generative-ai-models/\n",
    "# https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddfc496",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkSeaGreen\">Clean Up Architecture</span>\n",
    "### <span style=\"color:Red\">Only do this if you have finished with this lab and any labs that depend on it!</span>\n",
    "##### It will delete all architecture created, make sure you no longer need any of it!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when finished with the endpoint, delete it\n",
    "# This endpoint is deleted in lab 1\n",
    "# Remember to delete the architecture in lab 1 too"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
